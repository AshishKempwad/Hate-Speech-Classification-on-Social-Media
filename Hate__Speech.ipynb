{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTSPC- Hate Speech Classification on social media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read train data\n",
    "train = pd.read_csv('1fe720be-90e4-4e06-9b52-9de93e0ea937_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  @realDonaldTrump This is one of the worst time...       0\n",
       "1  How about the crowd in Oval in today's #AUSvIN...       1\n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...       0\n",
       "3  #etsy shop: Benedict Donald so called presiden...       1\n",
       "4  @realDonaldTrump Good build a wall around Arka...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "# print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5266 entries, 0 to 5265\n",
      "Data columns (total 2 columns):\n",
      "text      5266 non-null object\n",
      "labels    5266 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 82.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read test data\n",
    "test = pd.read_csv('final_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hasoc_en_902</td>\n",
       "      <td>West Bengal Doctor Crisis: Protesting doctors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hasoc_en_416</td>\n",
       "      <td>68.5 million people have been forced to leave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>hasoc_en_207</td>\n",
       "      <td>You came, you saw .... we will look after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>hasoc_en_595</td>\n",
       "      <td>We'll get Brexit delivered by October 31st.   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hasoc_en_568</td>\n",
       "      <td>Fuck you. Go back to the dark ages you cow @IB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       text_id                                               text\n",
       "0           0  hasoc_en_902  West Bengal Doctor Crisis: Protesting doctors ...\n",
       "1           1  hasoc_en_416  68.5 million people have been forced to leave ...\n",
       "2           2  hasoc_en_207  You came, you saw .... we will look after the ...\n",
       "3           3  hasoc_en_595  We'll get Brexit delivered by October 31st.   ...\n",
       "4           4  hasoc_en_568  Fuck you. Go back to the dark ages you cow @IB..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns='Unnamed: 0',inplace=True)\n",
    "test.drop(columns='text_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>West Bengal Doctor Crisis: Protesting doctors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.5 million people have been forced to leave ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You came, you saw .... we will look after the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We'll get Brexit delivered by October 31st.   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fuck you. Go back to the dark ages you cow @IB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  West Bengal Doctor Crisis: Protesting doctors ...\n",
       "1  68.5 million people have been forced to leave ...\n",
       "2  You came, you saw .... we will look after the ...\n",
       "3  We'll get Brexit delivered by October 31st.   ...\n",
       "4  Fuck you. Go back to the dark ages you cow @IB..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#We the labels(0/1) which signifies 'Hate speech(1)' or 'Not a hate speech(0) in of type int64 which we \n",
    "#convert to type category. We use 'astype' to cast the datatype\n",
    "\n",
    "train['labels'] = train['labels'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5266 entries, 0 to 5265\n",
      "Data columns (total 2 columns):\n",
      "text      5266 non-null object\n",
      "labels    5266 non-null category\n",
      "dtypes: category(1), object(1)\n",
      "memory usage: 46.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the comments/tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "train[\"text_w/o_url\"] = train[\"text\"].apply(lambda text: remove_urls(text))\n",
    "test[\"text_w/o_url\"] = test[\"text\"].apply(lambda text: remove_urls(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_w/o_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>0</td>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>1</td>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels  \\\n",
       "0  @realDonaldTrump This is one of the worst time...      0   \n",
       "1  How about the crowd in Oval in today's #AUSvIN...      1   \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...      0   \n",
       "3  #etsy shop: Benedict Donald so called presiden...      1   \n",
       "4  @realDonaldTrump Good build a wall around Arka...      0   \n",
       "\n",
       "                                        text_w/o_url  \n",
       "0  @realDonaldTrump This is one of the worst time...  \n",
       "1  How about the crowd in Oval in today's #AUSvIN...  \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...  \n",
       "3  #etsy shop: Benedict Donald so called presiden...  \n",
       "4  @realDonaldTrump Good build a wall around Arka...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...   \n",
      "1  68.5 million people have been forced to leave ...   \n",
      "2  You came, you saw .... we will look after the ...   \n",
      "3  We'll get Brexit delivered by October 31st.   ...   \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...   \n",
      "\n",
      "                                        text_w/o_url  \n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...  \n",
      "1  68.5 million people have been forced to leave ...  \n",
      "2  You came, you saw .... we will look after the ...  \n",
      "3  We'll get Brexit delivered by October 31st.   ...  \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...  \n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step  to remove all the special characters like '$,#,&,etc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Follow the below commands in case you havent downloaded nltk yet, in case you have downloaded you dont need this cell.\n",
    "##Steps/commands :\n",
    "\n",
    "#1) import nltk\n",
    "#2) nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]',' ',text)) for text in lis]) for lis in train['text_w/o_url']]\n",
    "test['text_lem'] = [''.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]',' ',text)) for text in lis]) for lis in test['text_w/o_url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can see the text after the removal of special characters under text_lem coloumn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_w/o_url</th>\n",
       "      <th>text_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>realDonaldTrump This is one of the worst time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>How about the crowd in Oval in today s  AUSvIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>0</td>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>skroskz  shossy   JoeBiden Biden  amp  his so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>1</td>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>etsy shop  Benedict Donald so called presiden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>realDonaldTrump Good build a wall around Arka...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels  \\\n",
       "0  @realDonaldTrump This is one of the worst time...      0   \n",
       "1  How about the crowd in Oval in today's #AUSvIN...      1   \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...      0   \n",
       "3  #etsy shop: Benedict Donald so called presiden...      1   \n",
       "4  @realDonaldTrump Good build a wall around Arka...      0   \n",
       "\n",
       "                                        text_w/o_url  \\\n",
       "0  @realDonaldTrump This is one of the worst time...   \n",
       "1  How about the crowd in Oval in today's #AUSvIN...   \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...   \n",
       "3  #etsy shop: Benedict Donald so called presiden...   \n",
       "4  @realDonaldTrump Good build a wall around Arka...   \n",
       "\n",
       "                                            text_lem  \n",
       "0   realDonaldTrump This is one of the worst time...  \n",
       "1  How about the crowd in Oval in today s  AUSvIN...  \n",
       "2   skroskz  shossy   JoeBiden Biden  amp  his so...  \n",
       "3   etsy shop  Benedict Donald so called presiden...  \n",
       "4   realDonaldTrump Good build a wall around Arka...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('We can see the text after the removal of special characters under text_lem coloumn')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...   \n",
      "1  68.5 million people have been forced to leave ...   \n",
      "2  You came, you saw .... we will look after the ...   \n",
      "3  We'll get Brexit delivered by October 31st.   ...   \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...   \n",
      "\n",
      "                                        text_w/o_url  \\\n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...   \n",
      "1  68.5 million people have been forced to leave ...   \n",
      "2  You came, you saw .... we will look after the ...   \n",
      "3  We'll get Brexit delivered by October 31st.   ...   \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...   \n",
      "\n",
      "                                            text_lem  \n",
      "0  West Bengal Doctor Crisis  Protesting doctors ...  \n",
      "1       million people have been forced to leave ...  \n",
      "2  You came  you saw      we will look after the ...  \n",
      "3  We ll get Brexit delivered by October   st    ...  \n",
      "4  Fuck you  Go back to the dark ages you cow  IB...  \n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step for spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "            \n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "           \n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "\n",
    "test[\"text_spell\"] = test[\"text_lem\"].apply(lambda text: correct_spellings(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text_spell\"] = train[\"text_lem\"].apply(lambda text: correct_spellings(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step for removing urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "train[\"text_w/o_url\"] = train[\"text_lem\"].apply(lambda text: remove_urls(text))\n",
    "test[\"text_w/o_url\"] = test[\"text_lem\"].apply(lambda text: remove_urls(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML tags removal step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  This step deals with removing the html tags but as removing these performed bad on our data,we arent using this pre-processing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_html(text):\n",
    "#     html_pattern = re.compile('<.*?>')\n",
    "#     return html_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "# train[\"text_w/o_html\"] = train[\"text_w/o_url\"].apply(lambda text: remove_html(text))\n",
    "# test[\"text_w/o_html\"] = test[\"text_w/o_url\"].apply(lambda text: remove_html(text))\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step  to remove the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In case you havent downloaded 'stopwards from nltk' yet use these below commands in case you already have downloaded \n",
    "#then you can skip this cell\n",
    "\n",
    "#Steps/Commands :\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are the stop words in English Language :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('The following are the stop words in English Language :')\n",
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "train[\"text_w/o_stop\"] = train[\"text_lem\"].apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "test[\"text_w/o_stop\"] = test[\"text_lem\"].apply(lambda text: remove_stopwords(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_w/o_url</th>\n",
       "      <th>text_lem</th>\n",
       "      <th>text_w/o_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>realDonaldTrump This one worst times American ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>How about the crowd in Oval in today s  AUSvIN...</td>\n",
       "      <td>How crowd Oval today AUSvIND holding Balidan b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>0</td>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>skroskz  shossy   JoeBiden Biden  amp  his so...</td>\n",
       "      <td>skroskz shossy JoeBiden Biden amp son Hunter t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>1</td>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>etsy shop  Benedict Donald so called presiden...</td>\n",
       "      <td>etsy shop Benedict Donald called president tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>realDonaldTrump Good build wall around Arkansa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels  \\\n",
       "0  @realDonaldTrump This is one of the worst time...      0   \n",
       "1  How about the crowd in Oval in today's #AUSvIN...      1   \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...      0   \n",
       "3  #etsy shop: Benedict Donald so called presiden...      1   \n",
       "4  @realDonaldTrump Good build a wall around Arka...      0   \n",
       "\n",
       "                                        text_w/o_url  \\\n",
       "0  @realDonaldTrump This is one of the worst time...   \n",
       "1  How about the crowd in Oval in today's #AUSvIN...   \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...   \n",
       "3  #etsy shop: Benedict Donald so called presiden...   \n",
       "4  @realDonaldTrump Good build a wall around Arka...   \n",
       "\n",
       "                                            text_lem  \\\n",
       "0   realDonaldTrump This is one of the worst time...   \n",
       "1  How about the crowd in Oval in today s  AUSvIN...   \n",
       "2   skroskz  shossy   JoeBiden Biden  amp  his so...   \n",
       "3   etsy shop  Benedict Donald so called presiden...   \n",
       "4   realDonaldTrump Good build a wall around Arka...   \n",
       "\n",
       "                                       text_w/o_stop  \n",
       "0  realDonaldTrump This one worst times American ...  \n",
       "1  How crowd Oval today AUSvIND holding Balidan b...  \n",
       "2  skroskz shossy JoeBiden Biden amp son Hunter t...  \n",
       "3  etsy shop Benedict Donald called president tra...  \n",
       "4  realDonaldTrump Good build wall around Arkansa...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...   \n",
      "1  68.5 million people have been forced to leave ...   \n",
      "2  You came, you saw .... we will look after the ...   \n",
      "3  We'll get Brexit delivered by October 31st.   ...   \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...   \n",
      "\n",
      "                                        text_w/o_url  \\\n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...   \n",
      "1  68.5 million people have been forced to leave ...   \n",
      "2  You came, you saw .... we will look after the ...   \n",
      "3  We'll get Brexit delivered by October 31st.   ...   \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...   \n",
      "\n",
      "                                            text_lem  \\\n",
      "0  West Bengal Doctor Crisis  Protesting doctors ...   \n",
      "1       million people have been forced to leave ...   \n",
      "2  You came  you saw      we will look after the ...   \n",
      "3  We ll get Brexit delivered by October   st    ...   \n",
      "4  Fuck you  Go back to the dark ages you cow  IB...   \n",
      "\n",
      "                                       text_w/o_stop  \n",
      "0  West Bengal Doctor Crisis Protesting doctors a...  \n",
      "1  million people forced leave homes Read refugee...  \n",
      "2                   You came saw look fort Good luck  \n",
      "3  We get Brexit delivered October st Help build ...  \n",
      "4  Fuck Go back dark ages cow IBNLiveRealtime Rap...  \n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step to convert emojis to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def convert_emojis(text):\n",
    "#     for emot in UNICODE_EMO:\n",
    "#         text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "#     return text\n",
    "\n",
    "# train[\"text_emo\"] = train[\"text_w/o_stop\"].apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "# test[\"text_emo\"] = test[\"text_w/o_stop\"].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>text_w/o_url</th>\n",
       "      <th>text_lem</th>\n",
       "      <th>text_w/o_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>realDonaldTrump This is one of the worst time...</td>\n",
       "      <td>realDonaldTrump This one worst times American ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>1</td>\n",
       "      <td>How about the crowd in Oval in today's #AUSvIN...</td>\n",
       "      <td>How about the crowd in Oval in today s  AUSvIN...</td>\n",
       "      <td>How crowd Oval today AUSvIND holding Balidan b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>0</td>\n",
       "      <td>@skroskz @shossy2 @JoeBiden Biden &amp;amp; his so...</td>\n",
       "      <td>skroskz  shossy   JoeBiden Biden  amp  his so...</td>\n",
       "      <td>skroskz shossy JoeBiden Biden amp son Hunter t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>1</td>\n",
       "      <td>#etsy shop: Benedict Donald so called presiden...</td>\n",
       "      <td>etsy shop  Benedict Donald so called presiden...</td>\n",
       "      <td>etsy shop Benedict Donald called president tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>0</td>\n",
       "      <td>@realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>realDonaldTrump Good build a wall around Arka...</td>\n",
       "      <td>realDonaldTrump Good build wall around Arkansa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels  \\\n",
       "0  @realDonaldTrump This is one of the worst time...       0   \n",
       "1  How about the crowd in Oval in today's #AUSvIN...       1   \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...       0   \n",
       "3  #etsy shop: Benedict Donald so called presiden...       1   \n",
       "4  @realDonaldTrump Good build a wall around Arka...       0   \n",
       "\n",
       "                                        text_w/o_url  \\\n",
       "0  @realDonaldTrump This is one of the worst time...   \n",
       "1  How about the crowd in Oval in today's #AUSvIN...   \n",
       "2  @skroskz @shossy2 @JoeBiden Biden &amp; his so...   \n",
       "3  #etsy shop: Benedict Donald so called presiden...   \n",
       "4  @realDonaldTrump Good build a wall around Arka...   \n",
       "\n",
       "                                            text_lem  \\\n",
       "0   realDonaldTrump This is one of the worst time...   \n",
       "1  How about the crowd in Oval in today s  AUSvIN...   \n",
       "2   skroskz  shossy   JoeBiden Biden  amp  his so...   \n",
       "3   etsy shop  Benedict Donald so called presiden...   \n",
       "4   realDonaldTrump Good build a wall around Arka...   \n",
       "\n",
       "                                       text_w/o_stop  \n",
       "0  realDonaldTrump This one worst times American ...  \n",
       "1  How crowd Oval today AUSvIND holding Balidan b...  \n",
       "2  skroskz shossy JoeBiden Biden amp son Hunter t...  \n",
       "3  etsy shop Benedict Donald called president tra...  \n",
       "4  realDonaldTrump Good build wall around Arkansa...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...   \n",
      "1  68.5 million people have been forced to leave ...   \n",
      "2  You came, you saw .... we will look after the ...   \n",
      "3  We'll get Brexit delivered by October 31st.   ...   \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...   \n",
      "\n",
      "                                        text_w/o_url  \\\n",
      "0  West Bengal Doctor Crisis: Protesting doctors ...   \n",
      "1  68.5 million people have been forced to leave ...   \n",
      "2  You came, you saw .... we will look after the ...   \n",
      "3  We'll get Brexit delivered by October 31st.   ...   \n",
      "4  Fuck you. Go back to the dark ages you cow @IB...   \n",
      "\n",
      "                                            text_lem  \\\n",
      "0  West Bengal Doctor Crisis  Protesting doctors ...   \n",
      "1       million people have been forced to leave ...   \n",
      "2  You came  you saw      we will look after the ...   \n",
      "3  We ll get Brexit delivered by October   st    ...   \n",
      "4  Fuck you  Go back to the dark ages you cow  IB...   \n",
      "\n",
      "                                       text_w/o_stop  \n",
      "0  West Bengal Doctor Crisis Protesting doctors a...  \n",
      "1  million people forced leave homes Read refugee...  \n",
      "2                   You came saw look fort Good luck  \n",
      "3  We get Brexit delivered October st Help build ...  \n",
      "4  Fuck Go back dark ages cow IBNLiveRealtime Rap...  \n"
     ]
    }
   ],
   "source": [
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(train['text_lem'],train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer().fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_transformed_X_train = vect.transform(X_train)\n",
    "vect_transformed_X_test = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifing the data using the following algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "modelSVC = SVC(C=500).fit(vect_transformed_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score using SVm with C=100 is :\n",
      "0.7698783910196446\n",
      "The accuracy using SVM with C=100 is :\n",
      "0.6264236902050114\n"
     ]
    }
   ],
   "source": [
    "predictionsSVC = modelSVC.predict(vect_transformed_X_test)\n",
    "# sum(predictionsSVC==1),len(y_test),\n",
    "print('The F1 score using SVm with C=100 is :')\n",
    "print(f1_score(y_test,predictionsSVC))\n",
    "print('The accuracy using SVM with C=100 is :')\n",
    "print(accuracy_score(y_test,predictionsSVC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "modelLR = LogisticRegression().fit(vect_transformed_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score using LR  is :\n",
      "0.7793176972281448\n",
      "The accuracy using LR is :\n",
      "0.6856492027334852\n"
     ]
    }
   ],
   "source": [
    "predictionsLR = modelLR.predict(vect_transformed_X_test)\n",
    "print('The F1 score using LR  is :')\n",
    "print(f1_score(y_test,predictionsLR))\n",
    "print('The accuracy using LR is :')\n",
    "print(accuracy_score(y_test,predictionsLR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNB = MultinomialNB(alpha=1).fit(vect_transformed_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 score using NB  is :\n",
      "0.7735941320293398\n",
      "The accuracy using NB  is :\n",
      "0.6484434320425209\n"
     ]
    }
   ],
   "source": [
    "predictionsNB = modelNB.predict(vect_transformed_X_test)\n",
    "print('The F1 score using NB  is :')\n",
    "print(f1_score(y_test,predictionsNB))\n",
    "print('The accuracy using NB  is :')\n",
    "print(accuracy_score(y_test,predictionsNB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRF = RandomForestClassifier(n_estimators=127).fit(vect_transformed_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7562028047464942"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsRF = modelRF.predict(vect_transformed_X_test)\n",
    "f1_score(y_test,predictionsRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer().fit(train['text_lem'])\n",
    "vect_transformed_train = vect.transform(train['text_lem'])\n",
    "vect_transformed_test = vect.transform(test['text_lem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashish/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "FinalModel = LogisticRegression().fit(vect_transformed_train,train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN = MultinomialNB(alpha=0.9).fit(vect_transformed_train,train['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = FN.predict(vect_transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'labels':predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Final_submission.csv'\n",
    "submission.to_csv(file_name,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels\n",
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(predictions==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello=pd.read_csv('Final_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(hello['labels']==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1153, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
